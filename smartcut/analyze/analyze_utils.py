""" """

from __future__ import annotations

from datetime import datetime
import json
from pathlib import Path

from shared.models.config_manager import CONFIG
from shared.utils.config import TMP_FRAMES_DIR_SC
from shared.utils.logger import get_logger
from smartcut.models_sc.ai_result import AIResult
from smartcut.models_sc.smartcut_model import SmartCutSession
from smartcut.norm_keywords.keyword_normalizer import KeywordNormalizer

logger = get_logger(__name__)

QBIT = CONFIG.smartcut["analyse_segment"]["4bit"]
BFLOAT16 = CONFIG.smartcut["analyse_segment"]["bfloat16"]
FLOAT16 = CONFIG.smartcut["analyse_segment"]["float16"]
FLOAT32 = CONFIG.smartcut["analyse_segment"]["float32"]
DEFAULT = CONFIG.smartcut["analyse_segment"]["default"]


def estimate_safe_batch_size(
    free_vram_gb: float,
    model_precision: str = "4bit",  # "bfloat16", "float16", etc.
    safety_margin_gb: float = 1.0,
) -> int:
    """
    Estime dynamiquement un batch size sÃ»r en fonction de la VRAM libre.
    """
    # Estimations empiriques Ã  adapter si besoin
    est_mem_per_image = {
        "4bit": QBIT,
        "bfloat16": BFLOAT16,
        "float16": FLOAT16,
        "float32": FLOAT32,
    }.get(model_precision, DEFAULT)

    usable_vram = max(0, free_vram_gb - safety_margin_gb)
    batch_size = int(usable_vram / est_mem_per_image)
    return max(1, batch_size)


def compute_num_frames(segment_duration: float, base_rate: int = 5) -> int:
    """
    Compute number of frames to extract dynamically.

    - base_rate: number of frames per minute of video.
    - Minimum 3 frames per segment.
    """
    frames = max(3, int(base_rate * (segment_duration / 60)))
    logger.debug(f"({base_rate} * ({segment_duration} / 60) : {frames}")
    return frames


def merge_keywords_across_batches(batch_outputs: list[AIResult]) -> tuple[str, list[str]]:
    """
    Fusionne plusieurs rÃ©ponses contenant des descriptions et des mots-clÃ©s.

    - GÃ¨re les formats :
        - JSON : {"Description": "...", "Keywords": ["mot1", "mot2", ...]}
        - Texte brut : "mot1, mot2, mot3"
    - Supprime les doublons et trie les mots.
    - ConcatÃ¨ne les descriptions de maniÃ¨re lisible.

    Retourne :
        (description_finale: str, keywords_uniques: list[str])
    """

    all_keywords: list[str] = []
    all_descriptions = []

    for item in batch_outputs:
        # Si c'est dÃ©jÃ  un dictionnaire Python
        if isinstance(item, dict):
            if "keywords" in item:
                all_keywords.extend(item["keywords"])
            if "description" in item:
                desc = item["description"].strip()
                if desc:
                    all_descriptions.append(desc)

        # Si c'est une chaÃ®ne
        elif isinstance(item, str):
            try:
                # Tente de parser comme JSON
                parsed = json.loads(item)
                if "Keywords" in parsed:
                    all_keywords.extend(parsed["Keywords"])
                if "Description" in parsed:
                    desc = parsed["Description"].strip()
                    if desc:
                        all_descriptions.append(desc)
            except json.JSONDecodeError:
                # Sinon, traite comme une simple liste de mots sÃ©parÃ©s par des virgules
                for kw in item.split(","):
                    clean_kw = kw.strip().lower()
                    if clean_kw:
                        all_keywords.append(clean_kw)

    # Nettoyage et tri
    unique_keywords = sorted({kw.lower() for kw in all_keywords})
    merged_description = " ".join(all_descriptions).strip()

    return merged_description, unique_keywords


def delete_frames(path: Path = Path(TMP_FRAMES_DIR_SC)) -> None:
    for file in Path(path).glob("*.jpg"):
        # logger.debug(f"ğŸ§¹ VÃ©rifiÃ© : {file.name}")
        try:
            file.unlink()
            # logger.debug(f"ğŸ§¹ SupprimÃ© : {file.name}")
        except Exception as e:
            logger.warning(f"âš ï¸ Impossible de supprimer {file.name} : {e}")


def update_session_keywords(
    session: SmartCutSession,
    start: float,
    end: float,
    keywords_list: list[str],
) -> None:
    for segment in session.segments:
        if abs(segment.start - start) < 0.01 and abs(segment.end - end) < 0.01:
            normalizer = KeywordNormalizer(mode="mixed")
            keywords_norm = normalizer.normalize_keywords(keywords_list)

            logger.info(f"{keywords_list} â†’ {keywords_norm}")
            segment.keywords = keywords_norm
            segment.ai_status = "done"
            SmartCutSession.last_updated = datetime.now().isoformat()

            session.save()
            logger.debug(
                f"ğŸ’¾ Sauvegarde JSON : segment {segment.id} "
                f"({start:.1f}s â†’ {end:.1f}s) [{len(keywords_norm)} mots-clÃ©s]"
            )
            break
