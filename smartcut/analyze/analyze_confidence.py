"""
üîé smartcut.analyze.analyze_confidence
-------------------------------------
Calcule un score de confiance entre la description IA et les mots-cl√©s d‚Äôun segment.
Utilise Sentence Transformers (ex: all-MiniLM-L6-v2 ou BAAI/bge-m3).
"""

from __future__ import annotations

from sentence_transformers import SentenceTransformer, util
import torch

from shared.models.config_manager import CONFIG
from shared.utils.logger import get_logger

logger = get_logger(__name__)

MODEL_CONFIDENCE: str = CONFIG.smartcut["analyse_confidence"]["model_confidence"]
DEVICE: str = CONFIG.smartcut["analyse_confidence"]["device"]

# üîß Initialisation du mod√®le global
MODEL = None


def get_confidence_model() -> SentenceTransformer:
    """
    Charge le mod√®le de similarit√© en m√©moire (lazy-load, CPU par d√©faut).
    """
    global MODEL, DEVICE
    if MODEL is not None:
        return MODEL

    try:
        # üí° V√©rifie si le GPU est dispo, mais reste CPU par d√©faut
        if torch.cuda.is_available():
            total_mem = torch.cuda.get_device_properties(0).total_memory
            if total_mem >= 16 * 1024**3:
                DEVICE = "cuda"
                logger.info("‚öôÔ∏è GPU d√©tect√© ‚Äî mod√®le sur CUDA (VRAM >= 16 Go)")
            else:
                logger.info("‚öôÔ∏è GPU limit√© ‚Äî mod√®le forc√© sur CPU")
        else:
            logger.info("‚öôÔ∏è Pas de GPU d√©tect√© ‚Äî mod√®le forc√© sur CPU")

        MODEL = SentenceTransformer(MODEL_CONFIDENCE, device=DEVICE)
        logger.info(f"‚úÖ Mod√®le de similarit√© charg√© sur {DEVICE.upper()} : {MODEL_CONFIDENCE}")

    except Exception as e:
        logger.error(f"‚ùå Erreur chargement mod√®le confiance : {e}")
        MODEL = None

    return MODEL


def compute_confidence(description: str, keywords: list[str]) -> float:
    """
    Calcule un score de confiance entre la description et les mots-cl√©s associ√©s.

    Retourne un score entre 0.0 et 1.0 bas√© sur la similarit√© cosinus.
    Si le mod√®le n‚Äôest pas dispo ou les champs vides ‚Üí renvoie 0.0.
    """
    try:
        if not description or not keywords:
            return 0.0

        model = get_confidence_model()
        if not model:
            logger.warning("‚ö†Ô∏è Aucun mod√®le disponible pour le calcul de confiance.")
            return 0.0

        text_keywords = ", ".join(keywords)

        # üîπ Encodage CPU/GPU auto
        desc_emb = model.encode(description, convert_to_tensor=True)
        key_emb = model.encode(text_keywords, convert_to_tensor=True)

        score: float = util.cos_sim(desc_emb, key_emb).item()
        score = max(0.0, min(1.0, float(score)))

        logger.debug(f"üîπ Score de confiance : {score:.3f} (desc='{description[:30]}...')")
        return round(score, 3)

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Erreur calcul confiance : {e}")
        return 0.0


if __name__ == "__main__":
    desc = "Un chat dort sur une chaise en bois."
    keywords = ["chat", "sieste", "chaise", "int√©rieur"]
    print(compute_confidence(desc, keywords))
